{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11202d19",
   "metadata": {},
   "source": [
    "# Exploring Mental Health Data\n",
    "**Objective:** Predict whether an individual suffers from depression based on a set of responses from a mental health survey.\n",
    "\n",
    "**Problem task:** Binary classification on the target variable depression (0 = false, 1 = true)\n",
    "\n",
    "**Dataset source:** Kaggle - Playground Series S4E11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92346d36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:02:58.277971Z",
     "start_time": "2025-05-12T14:02:57.989171Z"
    }
   },
   "outputs": [],
   "source": [
    "#Marta path:\n",
    "#Ricardo path:\n",
    "#Sara path: \"/Users/saracortez/feup/3o ano/iart/exploring_mental_health_data/data/train.csv\"\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"/Users/saracortez/feup/3o ano/iart/exploring_mental_health_data/data/train.csv\")\n",
    "test_data = pd.read_csv(\"/Users/saracortez/feup/3o ano/iart/exploring_mental_health_data/data/test.csv\")\n",
    "\n",
    "print(train_data.head())\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9efd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:02:58.482581Z",
     "start_time": "2025-05-12T14:02:58.346302Z"
    }
   },
   "outputs": [],
   "source": [
    "#duplicate removal\n",
    "bf = len(train_data)\n",
    "print(f\"Number of rows before removing duplicates: {len(train_data)}\")\n",
    "train_data = train_data.drop_duplicates()\n",
    "af = len(train_data)\n",
    "print(f\"Number of rows after removing duplicates: {len(train_data)}\")\n",
    "if (bf-af) == 0:\n",
    "    print(\"(No dup data found)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6de5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:02:58.596244Z",
     "start_time": "2025-05-12T14:02:58.535537Z"
    }
   },
   "outputs": [],
   "source": [
    "#missing value check\n",
    "def missing_value_info(df):\n",
    "    total = df.isnull().sum()\n",
    "    percent = (total / len(df)) * 100\n",
    "    return pd.DataFrame({'Missing Values': total, 'Percent Missing': percent}).sort_values(by='Percent Missing', ascending=False)\n",
    "missing_info_with_0 = missing_value_info(train_data)\n",
    "missing_info = missing_info_with_0[missing_info_with_0['Percent Missing'] > 0.0]\n",
    "print(missing_info)\n",
    "print(missing_info_with_0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b5bd7f",
   "metadata": {},
   "source": [
    "since these columns were spotted for missing values, we want to understand their appearance: how many are missing (NaN count in value_counts), if there unexpected 0s or negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf28ee7",
   "metadata": {},
   "source": [
    "### Data prepp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e037ebc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:02:58.685835Z",
     "start_time": "2025-05-12T14:02:58.658439Z"
    }
   },
   "outputs": [],
   "source": [
    "#train_data['Study Satisfaction'].value_counts(dropna=False)\n",
    "#train_data['Academic Pressure'].value_counts(dropna=False)\n",
    "#train_data['CGPA'].value_counts(dropna=False)\n",
    "#train_data['Profession'].value_counts(dropna=False)\n",
    "#train_data['Work Pressure'].value_counts(dropna=False)\n",
    "#train_data['Job Satisfaction'].value_counts(dropna=False)\n",
    "#train_data['Dietary Habits'].value_counts(dropna=False)\n",
    "#train_data['Financial Stress'].value_counts(dropna=False)\n",
    "pd.set_option('display.max_rows', None)\n",
    "train_data['Degree'].value_counts(dropna=False)\n",
    "#regulated\n",
    "#Comclusion: all our missing vals are NANS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873306d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forçar a visualização completa das contagens\n",
    "pd.set_option('display.max_rows', None)  # Isso vai permitir que todos os valores sejam exibidos\n",
    "print(train_data['Profession'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660de5c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:02:58.823839Z",
     "start_time": "2025-05-12T14:02:58.761838Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data['Profession'].value_counts(dropna=False)\n",
    "\n",
    "valid_professions = [\n",
    "    \"Teacher\", \"Content Writer\", \"Architect\", \"Consultant\", \"HR Manager\",\n",
    "    \"Pharmacist\", \"Doctor\", \"Business Analyst\", \"Entrepreneur\", \"Chemist\",\n",
    "    \"Chef\", \"Educational Consultant\", \"Data Scientist\", \"Researcher\", \"Lawyer\",\n",
    "    \"Customer Support\", \"Marketing Manager\", \"Pilot\", \"Travel Consultant\",\n",
    "    \"Plumber\", \"Sales Executive\", \"Manager\", \"Judge\", \"Electrician\",\n",
    "    \"Financial Analyst\", \"Software Engineer\", \"Civil Engineer\", \"UX/UI Designer\",\n",
    "    \"Digital Marketer\", \"Accountant\", \"Mechanical Engineer\", \"Graphic Designer\",\n",
    "    \"Research Analyst\", \"Investment Banker\", \"Analyst\", \"Academic\", \"Unemployed\", \"Medical Doctor\", \"City Manager\", \"Family Consultant\"\n",
    "]\n",
    "\n",
    "# corrigir erros digitação\n",
    "def correct_profession(value):\n",
    "    corrections = {\n",
    "        \"Finanancial Analyst\": \"Financial Analyst\",\n",
    "        # Adicionar mais ??\n",
    "    }\n",
    "    return corrections.get(value, value)\n",
    "\n",
    "train_data['Profession'] = train_data['Profession'].apply(correct_profession)\n",
    "\n",
    "test_data['Profession'] = test_data['Profession'].apply(correct_profession)\n",
    "\n",
    "def clean_profession(value):\n",
    "    if pd.isna(value):\n",
    "        return value  # mantém NaN\n",
    "    return value if value in valid_professions else \"other\"\n",
    "\n",
    "train_data['Profession'] = train_data['Profession'].apply(clean_profession)\n",
    "test_data['Profession'] = test_data['Profession'].apply(clean_profession)\n",
    "\n",
    "train_data['Profession'].value_counts(dropna=False)\n",
    "\n",
    "test_data['Profession'].value_counts(dropna=False)\n",
    "\n",
    "# these are names: [\"Yogesh\", \"Pranav\", \"Dev\", \"Yuvraj\"]\n",
    "# these seem to be localities [\"Patna\", \"Visakhapatnam\", \"Nagpur\", \"FamilyVirar\"]\n",
    "# and these ? what are hey ? not jobs. [\"Patna\", \"Visakhapatnam\", \"Nagpur\", \"FamilyVirar\"]\n",
    "#degrees like MBA\n",
    "#substringing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a72413",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:02:59.400537Z",
     "start_time": "2025-05-12T14:02:58.906575Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# handle ranges like 6-8, handle more than/less than X,handle direct numeric values\n",
    "print(len(train_data['Sleep Duration']))\n",
    "#15 rows lost\n",
    "def normalize_sleep_duration(column):\n",
    "    def normalize(value):\n",
    "        value = str(value).strip()\n",
    "\n",
    "        match_range = re.match(r\"(\\d+)\\s*-\\s*(\\d+)\", value)\n",
    "        if match_range:\n",
    "            x, y = map(int, match_range.groups())\n",
    "            return (x + y) / 2\n",
    "\n",
    "        match_more = re.match(r\"More than (\\d+)\", value, re.IGNORECASE)\n",
    "        if match_more:\n",
    "            return int(match_more.group(1)) + 0.5\n",
    "\n",
    "        match_less = re.match(r\"Less than (\\d+)\", value, re.IGNORECASE)\n",
    "        if match_less:\n",
    "            return int(match_less.group(1)) - 0.5\n",
    "\n",
    "        try:\n",
    "            return float(value)\n",
    "        except ValueError:\n",
    "            return pd.NA \n",
    "\n",
    "    return column.apply(normalize)\n",
    "\n",
    "def normalize_large_sleep_values(column):\n",
    "    def adjust_large(value):\n",
    "        try:\n",
    "            if pd.notna(value) and value >= 12:\n",
    "                return round(value / 7 * 2) / 2\n",
    "            return value\n",
    "        except:\n",
    "            return pd.NA\n",
    "    return column.apply(adjust_large)\n",
    "\n",
    "train_data['Sleep Duration'] = normalize_sleep_duration(train_data['Sleep Duration'])\n",
    "train_data['Sleep Duration'] = normalize_large_sleep_values(train_data['Sleep Duration'])\n",
    "test_data['Sleep Duration'] = normalize_sleep_duration(test_data['Sleep Duration'])\n",
    "test_data['Sleep Duration'] = normalize_large_sleep_values(test_data['Sleep Duration'])\n",
    "\n",
    "print(train_data['Sleep Duration'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6d35ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:02:59.407590647Z",
     "start_time": "2025-05-12T13:59:33.294320Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_dietary = [\"Moderate\", \"Unhealthy\", \"Healthy\"]\n",
    "\n",
    "train_data[\"Dietary Habits\"] = train_data[\"Dietary Habits\"].apply(\n",
    "    lambda x: x if pd.isna(x) or x in valid_dietary else \"other\"\n",
    ")\n",
    "test_data[\"Dietary Habits\"] = test_data[\"Dietary Habits\"].apply(\n",
    "    lambda x: x if pd.isna(x) or x in valid_dietary else \"other\"\n",
    ")\n",
    "\n",
    "\n",
    "print(train_data['Dietary Habits'].value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_degree(column):\n",
    "    def clean(item):\n",
    "        if isinstance(item, str):\n",
    "            item = item.replace('.', '').replace(' ', '')\n",
    "            return item\n",
    "        else:\n",
    "            return 'invalid'\n",
    "    \n",
    "    column = column.apply(clean)\n",
    "    def remove_names(item):\n",
    "            if (len(item) > 1 and item[0].isupper() and item[1].isupper() and item[0] in ['L', 'P', 'B', 'M']) or item == 'Class12' or item == \"PhD\":\n",
    "                return item\n",
    "            else:\n",
    "                return 'invalid' \n",
    "    return column.apply(remove_names)\n",
    "#importante dar NA aos inválidos para dar drop\n",
    "train_data['Degree'] = normalize_degree(train_data['Degree'])\n",
    "test_data['Degree'] = normalize_degree(test_data['Degree'])\n",
    "\n",
    "degree_counts = train_data['Degree'].value_counts()\n",
    "rare_degrees = degree_counts[degree_counts <= 5].index\n",
    "\n",
    "train_data['Degree'] = train_data['Degree'].apply(lambda x: 'other' if x in rare_degrees else x)\n",
    "test_data['Degree'] = test_data['Degree'].apply(lambda x: 'other' if x in rare_degrees else x)\n",
    "     \n",
    "\n",
    "print(train_data['Degree'].value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d23e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data['Work/Study Hours'].value_counts(dropna=False))\n",
    "\"\"\"\n",
    "train_data['Work/Study Hours'].value_counts(dropna=False)\n",
    "train_data['Academic Pressure'].value_counts(dropna=False)\n",
    "train_data['CGPA'].value_counts(dropna=False)\n",
    "train_data['Profession'].value_counts(dropna=False)\n",
    "train_data['Work Pressure'].value_counts(dropna=False)\n",
    "train_data['Job Satisfaction'].value_counts(dropna=False)\n",
    "train_data['Dietary Habits'].value_counts(dropna=False)\n",
    "train_data['Financial Stress'].value_counts(dropna=False)\n",
    "train_data['Degree'].value_counts(dropna=False)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b2b0a8",
   "metadata": {},
   "source": [
    "we can detect in our data two categories of individuals, identifiable by their attributes:\n",
    "- **Students:** academic pressure, CGPA, study satisfaction, degree\n",
    "- **Worker Professionals:** work pressure, profession, job satisfaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec77f77",
   "metadata": {},
   "source": [
    "Our decision tree classifier requires binary values. Thus, let's convert bicategorical variables in to 0/1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd93a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gender column: Male -> 1, Female -> 0\n",
    "train_data['Gender'] = train_data['Gender'].replace({'Male': 1, 'Female': 0})\n",
    "train_data['Working Professional or Student'] = train_data['Working Professional or Student'].replace({'Working Professional': 1, 'Student': 0})\n",
    "\n",
    "# Have you ever had suicidal thoughts?\n",
    "train_data['Have you ever had suicidal thoughts ?'] = train_data['Have you ever had suicidal thoughts ?'].replace({'Yes': 1, 'No': 0})\n",
    "\n",
    "train_data['Family History of Mental Illness'] = train_data['Family History of Mental Illness'].replace({'Yes': 1, 'No': 0})\n",
    "\n",
    "test_data['Gender'] = test_data['Gender'].replace({'Male': 1, 'Female': 0})\n",
    "test_data['Working Professional or Student'] = test_data['Working Professional or Student'].replace({'Working Professional': 1, 'Student': 0})\n",
    "\n",
    "test_data['Have you ever had suicidal thoughts ?'] = test_data['Have you ever had suicidal thoughts ?'].replace({'Yes': 1, 'No': 0})\n",
    "\n",
    "test_data['Family History of Mental Illness'] = test_data['Family History of Mental Illness'].replace({'Yes': 1, 'No': 0})\n",
    "#print(train_data['Gender']).value_counts().sort(ascending=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cece835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNDERSAMPLING COM PRIORIDADE\n",
    "\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "\n",
    "X = train_data.drop(\"Depression\", axis=1)\n",
    "y = train_data[\"Depression\"]\n",
    "\n",
    "data = pd.concat([X, y], axis=1)\n",
    "\n",
    "class_counts = data[\"Depression\"].value_counts()\n",
    "min_class_size = class_counts.min()\n",
    "\n",
    "priority_cols = [\"Profession\", \"Degree\", \"Dietary Habits\"]\n",
    "\n",
    "balanced_data = []\n",
    "\n",
    "for label in class_counts.index:\n",
    "    subset = data[data[\"Depression\"] == label]\n",
    "\n",
    "    if len(subset) > min_class_size:\n",
    "        \n",
    "        to_keep = min_class_size\n",
    "        # Primeira prioridade: linhas com \"invalid\"\n",
    "        invalid_rows = subset[subset[priority_cols].isin([\"invalid\"]).any(axis=1)]\n",
    "        subset = subset.drop(invalid_rows.index)\n",
    "\n",
    "        # Segunda prioridade: linhas com \"other\"\n",
    "        other_rows = subset[subset[priority_cols].isin([\"other\"]).any(axis=1)]\n",
    "        subset = subset.drop(other_rows.index)\n",
    "\n",
    "        remaining_needed = to_keep\n",
    "\n",
    "\n",
    "        if len(subset) >= remaining_needed:\n",
    "            to_sample = subset.sample(remaining_needed, random_state=42)\n",
    "        else:\n",
    "            # Remover todos os 'priority' e sortear os restantes\n",
    "            rows_needed = remaining_needed - len(subset)\n",
    "\n",
    "            if len(other_rows) >= rows_needed:\n",
    "                to_sample = pd.concat([subset, other_rows.sample(rows_needed, random_state=42)])\n",
    "            else:\n",
    "                still_needed = rows_needed - len(other_rows)\n",
    "                to_sample = pd.concat([\n",
    "                    subset,\n",
    "                    other_rows,\n",
    "                    invalid_rows.sample(still_needed, random_state=42)\n",
    "                ])\n",
    "    else:\n",
    "\n",
    "        to_sample = subset\n",
    "\n",
    "    balanced_data.append(to_sample)\n",
    "\n",
    "undersampled_data = pd.concat(balanced_data)\n",
    "\n",
    "undersampled_data.to_csv(\"undersampled_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed31929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = undersampled_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff83619",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Satisfaction'] = train_data[['Job Satisfaction', 'Study Satisfaction']].mean(axis=1, skipna=True)\n",
    "\n",
    "train_data = train_data.drop(columns=['Job Satisfaction', 'Study Satisfaction'])\n",
    "train_data['Pressure'] = train_data[['Work Pressure', 'Academic Pressure']].mean(axis=1, skipna=True)\n",
    "\n",
    "train_data = train_data.drop(columns=['Work Pressure', 'Academic Pressure'])\n",
    "print(train_data[['Pressure']].head())\n",
    "\n",
    "print(train_data[['Satisfaction']].head())\n",
    "\n",
    "train_data.loc[train_data['CGPA'].notna() & train_data['Profession'].isna(), 'Profession'] = 'Student'\n",
    "train_data = train_data.drop(columns=['CGPA'])\n",
    "print(train_data[['Profession']].head())\n",
    "\n",
    "test_data['Satisfaction'] = test_data[['Job Satisfaction', 'Study Satisfaction']].mean(axis=1, skipna=True)\n",
    "\n",
    "test_data = test_data.drop(columns=['Job Satisfaction', 'Study Satisfaction'])\n",
    "test_data['Pressure'] = test_data[['Work Pressure', 'Academic Pressure']].mean(axis=1, skipna=True)\n",
    "\n",
    "test_data = test_data.drop(columns=['Work Pressure', 'Academic Pressure'])\n",
    "\n",
    "\n",
    "test_data.loc[test_data['CGPA'].notna() & test_data['Profession'].isna(), 'Profession'] = 'Student'\n",
    "test_data = test_data.drop(columns=['CGPA'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1607b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train_merge.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd5e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"test_merge.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data_clean = pd.read_csv(\"train_merge.csv\")\n",
    "print(train_data_clean.columns)\n",
    "print(train_data_clean.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50a3c8d",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0858db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "sb.scatterplot(x='Work/Study Hours', y='Sleep Duration',\n",
    "                hue='Have you ever had suicidal thoughts ?', data=train_data_clean)\n",
    "plt.title('Work Hours vs. Sleep Duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f1b45e",
   "metadata": {},
   "source": [
    "ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a030350",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(train_data_clean[[\n",
    "    'Satisfaction', 'Sleep Duration', 'Work/Study Hours',\n",
    "    'Have you ever had suicidal thoughts ?'\n",
    "]], hue='Have you ever had suicidal thoughts ?')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8ed334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "training_data = train_data_clean.copy()\n",
    "\n",
    "training_data.drop(columns=['id', 'Name', 'City', 'Profession'], inplace=True)\n",
    "\n",
    "categorical_cols = training_data.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    training_data[col] = le.fit_transform(training_data[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "X = training_data.drop(columns=['Depression'])\n",
    "y = training_data['Depression']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "cf_mx = confusion_matrix(y_val, y_pred)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion matrix\\n\", cf_mx)\n",
    "    #ACCURACY DE 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "\n",
    "X_val_imputed = imputer.transform(X_val)\n",
    "\n",
    "clf = MLPClassifier(max_iter=1000)\n",
    "clf.fit(X_train_imputed, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_val_imputed)\n",
    "\n",
    "cf_mx = confusion_matrix(y_val, y_pred)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion matrix\\n\", cf_mx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
